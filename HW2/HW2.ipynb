{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_204249239_308402163.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7K1lIKisGq0",
        "colab_type": "text"
      },
      "source": [
        "# HW2\n",
        "### Or Wolkimir (308402163) and Afek Adler (204249239) \n",
        "This is our solution for applying 2 different architectures of LSTM and GRU for sequence2sequence task.\n",
        "All configurations can be changed in the **config** section. There is no reason to manipulate other code sections.\n",
        "\n",
        "For implementing different architectures we used pytorch build-in **nn.ModuleDict**.\n",
        "\n",
        "**For the ease of convience for the checker, we leave the code with default args that make the model run for short time (40 epochs, with uploading weights at each epoch). Should be around 90 Seconds.** if you wish to make it shorter you can decrease the number of epochs .\n",
        "\n",
        "The code Was written in this fashion in order to be **easily modified and extended** (more complicated scinerios) so maybe it appears to have some code overhead.\n",
        "\n",
        "We added our graphs (for ~40 epochs and detailed explanations in the attached pdf)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nikv0sDysAov",
        "colab_type": "code",
        "outputId": "0b9cc723-eefc-4e7e-c082-0f6537bd78c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "!pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import helper\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import summary\n",
        "import datetime\n",
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "from os import mkdir\n",
        "from os.path import isdir\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "import pandas as pd    \n",
        "from torch.autograd import Variable\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlJILpSMJa4U",
        "colab_type": "text"
      },
      "source": [
        "# 1.Mount\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXKZpOIrkGgc",
        "colab_type": "code",
        "outputId": "43b7578d-301f-4dab-e406-504cc75c8d6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7_wvHByJpw2",
        "colab_type": "text"
      },
      "source": [
        "# 2.Default Config\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfYOxpv8JpDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "# IO\n",
        "ROOT_PATH =  Path('/content/drive/My Drive/university/projects/DL/HW2/ex2_204249239_308402163/')\n",
        "TRAIN_PATH =  ROOT_PATH/'PTB/ptb.train.txt'\n",
        "VALID_PATH =  ROOT_PATH/'PTB/ptb.valid.txt'\n",
        "TEST_PATH =  ROOT_PATH/'PTB/ptb.test.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLKZyjtfJhSy",
        "colab_type": "text"
      },
      "source": [
        "# 3. IO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbz0Qiyo0Q22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(TRAIN_PATH, 'r') as train_loader:\n",
        "    train = train_loader.read()\n",
        "with open(VALID_PATH, 'r') as validation_loader:\n",
        "    validation = validation_loader.read()\n",
        "with open(TEST_PATH, 'r') as test_loader:\n",
        "    test = test_loader.read()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNw7B1OuDY1z",
        "colab_type": "text"
      },
      "source": [
        "# 4. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFf2IK0O18am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def words_to_int(l, translator):\n",
        "  return   [translator[w] for w in l if w != \" \"]\n",
        "\n",
        "counts = Counter(train.split())\n",
        "words = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(words, 1)}\n",
        "int_to_vocab = {i: v for i,v in vocab_to_int.items()}\n",
        "train = np.array(words_to_int(train.split(), vocab_to_int))\n",
        "validation = np.array(words_to_int(validation.split(), vocab_to_int))\n",
        "test = np.array(words_to_int(test.split(), vocab_to_int))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAR4o1dbup70",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 get batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ6XaIovRH5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(arr,batch_size = 20, seq_length = 20):\n",
        "    batch_size_total = batch_size * seq_length\n",
        "    n_batches = (len(arr)-1) // batch_size_total\n",
        "    x , y =  arr[:-1], arr[1:]\n",
        "    x = x[:n_batches * batch_size_total]\n",
        "    y = y[:n_batches * batch_size_total]\n",
        "    x = x.reshape((batch_size, -1))\n",
        "    y = y.reshape((batch_size, -1))\n",
        "    for n in range(0, x.shape[1], seq_length):\n",
        "      yield x[:, n:n + seq_length],y[:, n:n + seq_length]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJp5M833tW-t",
        "colab_type": "text"
      },
      "source": [
        "# 5. Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ItnuQdeAL6E0",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self,config):\n",
        "    super().__init__()\n",
        "    self.cell_type = config.cell_type\n",
        "    self.n_recurrent_layers = config.n_recurrent_layers\n",
        "    vocab_size, word_embedding_dim = 10000 ,config.word_embedding_dim\n",
        "    self.rnn_embedding_dim =  config.rnn_embedding_dim\n",
        "    self.dropout_rate= config.dropout_rate\n",
        "    self.embeddings = nn.Embedding(vocab_size, word_embedding_dim)\n",
        "    self.rnn = self.get_memory_cell_type(word_embedding_dim,self.rnn_embedding_dim,self.n_recurrent_layers)\n",
        "    self.fc = nn.Linear(self.rnn_embedding_dim, vocab_size) \n",
        "    self.regulizer = self.get_regulizer(config.apply_dropout,self.rnn_embedding_dim)\n",
        "\n",
        "\n",
        "  def forward(self, x, hidden):\n",
        "    embeds = self.embeddings(x)\n",
        "    r_output, hidden = self.rnn(embeds, hidden)\n",
        "    out = self.regulizer(r_output) \n",
        "    out = out.contiguous().view(-1, self.rnn_embedding_dim)\n",
        "    out = self.fc(out)\n",
        "    return out, hidden\n",
        "\n",
        "  def get_regulizer(self,regulizer,hidden_layer_size):\n",
        "    regulizer = 'dropout' if regulizer == True else 'no_regulizer'\n",
        "    regulizers = nn.ModuleDict([\n",
        "                ['dropout', nn.Dropout(self.dropout_rate)],\n",
        "                ['no_regulizer', nn.Identity(hidden_layer_size)]])\n",
        "    return regulizers[regulizer]\n",
        "\n",
        "  def get_memory_cell_type(self,in_dim, out_dim,num_layers):\n",
        "    memory_cells = nn.ModuleDict([\n",
        "                ['GRU', nn.GRU(in_dim, out_dim, self.n_recurrent_layers,batch_first=True,dropout=self.dropout_rate)],\n",
        "                ['LSTM', nn.LSTM(in_dim, out_dim, self.n_recurrent_layers,batch_first=True,dropout=self.dropout_rate)]])\n",
        "    return memory_cells[self.cell_type]\n",
        "\n",
        "  def init_hidden(self, batch_size, device):\n",
        "    weight = next(self.parameters()).data # understand what is it\n",
        "    if self.cell_type =='GRU':\n",
        "      return weight.new(self.n_recurrent_layers, batch_size, self.rnn_embedding_dim).zero_().to(device)\n",
        "    else: #LSTM\n",
        "      return (weight.new(self.n_recurrent_layers, batch_size, self.rnn_embedding_dim).zero_().to(device),\n",
        "          weight.new(self.n_recurrent_layers, batch_size, self.rnn_embedding_dim).zero_().to(device))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hCdY13_q0Al",
        "colab_type": "text"
      },
      "source": [
        "# 4. Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDnoTlxf5C9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer:\n",
        "  def __init__(self,config):\n",
        "    self.model = RNN(config)\n",
        "    self.model_name = config.exp_name\n",
        "    self.seed = config.seed\n",
        "    self.lr = config.lr\n",
        "    self.epochs = config.epochs\n",
        "    self.save_model = config.save_model\n",
        "    self.batch_size = config.batch_size\n",
        "    self.upload_model = config.upload_model\n",
        "    self.model_weights_path = config.model_weights_path\n",
        "    self.sequence_len = config.sequence_len\n",
        "    self.weight_decay = config.weight_decay\n",
        "    self.optimizer =  optim.SGD(self.model.parameters(), lr = self.lr, momentum=0.92, nesterov=False, weight_decay= self.weight_decay)\n",
        "    torch.manual_seed(self.seed)\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    self.results = {}\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.clip = 5\n",
        "    if torch.cuda.is_available():\n",
        "      self.model.to(self.device)\n",
        "\n",
        "  def get_results(self):\n",
        "    return pd.DataFrame.from_dict(self.results)\n",
        "\n",
        "  def record(self,epoch,**kwargs):\n",
        "    epoch = \"{:02d}\".format(epoch)\n",
        "    temp = f\"| epoch   # {epoch} :\"\n",
        "    for key, value in kwargs.items():\n",
        "      key = f\"{self.model_name}_{key}\"\n",
        "      if not self.results.get(key):\n",
        "        self.results[key] =[]\n",
        "      self.results[key].append(value)\n",
        "      val = '{:.2f}'.format(np.round(value,2))\n",
        "      temp += f\"{key} : {val}      |       \"\n",
        "      \n",
        "    print(temp)\n",
        "\n",
        "  def lr_scheduler(self,epoch):\n",
        "    if 25 > epoch >= 4:\n",
        "      self.lr *= 0.9\n",
        "    if epoch ==25:\n",
        "      self.lr *= 0.1\n",
        "    if epoch > 25:\n",
        "      self.lr *= 0.7      \n",
        "\n",
        "  def fit(self,train,validation,test, exp_name): \n",
        "    train_accu, test_accu = [],[]\n",
        "    for epoch in range(1,self.epochs+1):\n",
        "      self.lr_scheduler(epoch)\n",
        "      weights_path = Path(f\"{self.model_weights_path}/{self.model_name}_{epoch}.pth\")\n",
        "      if weights_path.exists() and self.upload_model:\n",
        "        epoch_train_loss = self.load_checkpoint(weights_path,epoch)\n",
        "      else:\n",
        "        epoch_train_loss = self.run_epoch(train)\n",
        "      epoch_test_loss = self.test(validation)\n",
        "      self.record(epoch,train_loss = epoch_train_loss, validation_loss = epoch_test_loss)\n",
        "      self.save_checkpoint(weights_path,epoch_train_loss)\n",
        "    test_loss = self.test(test)\n",
        "    padding = '*'*40\n",
        "    print(f\"{padding} TEST LOSS : {test_loss} {padding}\")\n",
        "\n",
        "  def get_hidden_no_grad(self,h):\n",
        "      if self.model.cell_type == 'GRU':\n",
        "        h = h.data\n",
        "      else:\n",
        "        h = tuple([each.data for each in h])\n",
        "      return h\n",
        "\n",
        "\n",
        "  def run_epoch(self,data):\n",
        "    train_loss , counter = 0 , 0\n",
        "    self.model.train()\n",
        "    h = self.model.init_hidden(self.batch_size,self.device)\n",
        "    for i, (x, y) in enumerate(get_batches(data, self.batch_size,self.sequence_len)):\n",
        "      inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "      inputs = inputs.to(self.device)\n",
        "      targets = targets.to(self.device, dtype=torch.int64)\n",
        "      h = self.get_hidden_no_grad(h)\n",
        "      self.optimizer.zero_grad()\n",
        "      output, h = self.model(inputs, h)\n",
        "      loss = self.criterion(output, targets.reshape(-1))\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(self.model.parameters(), self.clip)\n",
        "      self.optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "      counter += 1\n",
        "    perplexity = np.exp(train_loss/counter)\n",
        "    return perplexity\n",
        "\n",
        "  def test(self,data):\n",
        "    self.model.eval()\n",
        "    test_loss, counter = 0, 0\n",
        "    with torch.no_grad():\n",
        "      h = self.model.init_hidden(self.batch_size,self.device)\n",
        "      for x,y in get_batches(data, self.batch_size,self.sequence_len):\n",
        "        inputs, targets = torch.from_numpy(x), torch.from_numpy(y)\n",
        "        inputs = inputs.to(self.device)\n",
        "        targets = targets.to(self.device, dtype=torch.int64)\n",
        "        h = self.get_hidden_no_grad(h)\n",
        "        output, h = self.model(inputs, h)\n",
        "        loss = self.criterion(output, targets.reshape(-1).long())\n",
        "        test_loss += loss.item()\n",
        "        counter += 1\n",
        "      perplexity = np.exp(test_loss/counter)\n",
        "      return perplexity\n",
        "    \n",
        "\n",
        "  def save_checkpoint(self,weights_path,loss):\n",
        "    if (not weights_path.exists()) and self.save_model: \n",
        "      torch.save({'model_state_dict': self.model.state_dict(),\n",
        "              'optimizer_state_dict': self.optimizer.state_dict(),'loss': loss}, weights_path)\n",
        "      \n",
        "  def load_checkpoint(self,weights_path,epoch):\n",
        "    checkpoint = torch.load(weights_path)\n",
        "    self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    self.model.to(self.device)\n",
        "    loss = checkpoint['loss']\n",
        "    print(f\"Uploaded weights succesfuly at epoch number {epoch}\")\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onXkQpn5q6IV",
        "colab_type": "text"
      },
      "source": [
        "# 5. Utils\n",
        "Utility functions for the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL71fO5LOKbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config:  \n",
        "  def __init__(self, **kwargs):\n",
        "    for key, value in kwargs.items():\n",
        "      setattr(self, key, value)\n",
        "\n",
        "  def add_attributes(self,**kwargs):\n",
        "    for key, value in kwargs.items():\n",
        "      setattr(self, key, value)\n",
        "\n",
        "def create_directories(l):\n",
        "  for directory_path in l:\n",
        "    if not (isdir(directory_path)):\n",
        "      mkdir(directory_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr7RLjwsrGOT",
        "colab_type": "text"
      },
      "source": [
        "# 5. experiments Config "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cayKUt5cjTq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NEURAL NET\n",
        "MODEL_WEIGHTS_DIR = 'model_weights'\n",
        "GRAPHS_FOLDER_NAME = 'graphs'\n",
        "model_weights_dir = ROOT_PATH/MODEL_WEIGHTS_DIR \n",
        "graphs_dir = ROOT_PATH/GRAPHS_FOLDER_NAME \n",
        "SAVE_FIGS = True\n",
        "\n",
        "def get_base_config():\n",
        "  ####################################################################\n",
        "  # model consistency options\n",
        "  SAVE_TO_CHECKPOINTS = True # if ture, saves model.name_epcoch file into the weights folder\n",
        "  LOAD_CHECKPOINTS = False # # if ture, every epoch tries to load pretrained weights\n",
        "  ####################################################################\n",
        "  # if needed, can be modified to upload the 'best model'\n",
        "\n",
        "  return Config(\n",
        "          seed = 42, lr = 0.2,epochs = 40,sequence_len = 20,\n",
        "          batch_size = 20, weight_decay = 0.00004,dropout_rate = 0.25,\n",
        "          n_recurrent_layers = 2, word_embedding_dim =200, rnn_embedding_dim = 200,\n",
        "          save_model = SAVE_TO_CHECKPOINTS,\n",
        "          upload_model = LOAD_CHECKPOINTS,\n",
        "          model_weights_path = model_weights_dir)\n",
        "\n",
        "EXPERIMENTS =  {'lstm_with_dropout':('LSTM',True),'gru_with_dropout':('GRU',True), 'lstm_no_dropout': ('LSTM',False),'gru_no_dropout':('GRU',False)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfnNkr9YpB5J",
        "colab_type": "text"
      },
      "source": [
        "# 7. Run experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07PKWDw5CHZz",
        "colab_type": "code",
        "outputId": "6386e676-2b7c-4bdb-a94f-a4f1c6ae240b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "def run_exp(experiments):\n",
        "  # create weights directory\n",
        "  create_directories([graphs_dir,model_weights_dir])\n",
        "  results = []\n",
        "  for exp_name,(cell_type , apply_dropout) in experiments.items():\n",
        "    print(f\"{'#'*118} \\n running {exp_name} experiment\\n{'#'*118}\") \n",
        "    config.add_attributes(exp_name = exp_name, apply_dropout = apply_dropout, cell_type = cell_type)\n",
        "    trainer = Trainer(config)\n",
        "    trainer.fit(train,validation,test,exp_name)\n",
        "    results.append(trainer.get_results())\n",
        "  return results\n",
        "\n",
        "config = get_base_config()\n",
        "results = run_exp(EXPERIMENTS)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###################################################################################################################### \n",
            " running lstm_with_dropout experiment\n",
            "######################################################################################################################\n",
            "| epoch   # 01 :lstm_with_dropout_train_loss : 460.30      |       lstm_with_dropout_validation_loss : 302.52      |       \n",
            "| epoch   # 02 :lstm_with_dropout_train_loss : 277.22      |       lstm_with_dropout_validation_loss : 242.08      |       \n",
            "| epoch   # 03 :lstm_with_dropout_train_loss : 232.27      |       lstm_with_dropout_validation_loss : 216.98      |       \n",
            "| epoch   # 04 :lstm_with_dropout_train_loss : 208.22      |       lstm_with_dropout_validation_loss : 201.81      |       \n",
            "| epoch   # 05 :lstm_with_dropout_train_loss : 192.80      |       lstm_with_dropout_validation_loss : 193.11      |       \n",
            "| epoch   # 06 :lstm_with_dropout_train_loss : 180.95      |       lstm_with_dropout_validation_loss : 184.30      |       \n",
            "| epoch   # 07 :lstm_with_dropout_train_loss : 170.84      |       lstm_with_dropout_validation_loss : 178.09      |       \n",
            "| epoch   # 08 :lstm_with_dropout_train_loss : 161.29      |       lstm_with_dropout_validation_loss : 170.74      |       \n",
            "| epoch   # 09 :lstm_with_dropout_train_loss : 152.75      |       lstm_with_dropout_validation_loss : 163.85      |       \n",
            "| epoch   # 10 :lstm_with_dropout_train_loss : 145.34      |       lstm_with_dropout_validation_loss : 160.41      |       \n",
            "| epoch   # 11 :lstm_with_dropout_train_loss : 139.24      |       lstm_with_dropout_validation_loss : 158.02      |       \n",
            "| epoch   # 12 :lstm_with_dropout_train_loss : 134.50      |       lstm_with_dropout_validation_loss : 153.73      |       \n",
            "| epoch   # 13 :lstm_with_dropout_train_loss : 130.66      |       lstm_with_dropout_validation_loss : 149.92      |       \n",
            "| epoch   # 14 :lstm_with_dropout_train_loss : 127.19      |       lstm_with_dropout_validation_loss : 150.86      |       \n",
            "| epoch   # 15 :lstm_with_dropout_train_loss : 124.47      |       lstm_with_dropout_validation_loss : 147.11      |       \n",
            "| epoch   # 16 :lstm_with_dropout_train_loss : 122.22      |       lstm_with_dropout_validation_loss : 147.61      |       \n",
            "| epoch   # 17 :lstm_with_dropout_train_loss : 120.27      |       lstm_with_dropout_validation_loss : 145.67      |       \n",
            "| epoch   # 18 :lstm_with_dropout_train_loss : 118.59      |       lstm_with_dropout_validation_loss : 143.21      |       \n",
            "| epoch   # 19 :lstm_with_dropout_train_loss : 116.95      |       lstm_with_dropout_validation_loss : 142.39      |       \n",
            "| epoch   # 20 :lstm_with_dropout_train_loss : 115.63      |       lstm_with_dropout_validation_loss : 144.07      |       \n",
            "| epoch   # 21 :lstm_with_dropout_train_loss : 114.39      |       lstm_with_dropout_validation_loss : 142.77      |       \n",
            "| epoch   # 22 :lstm_with_dropout_train_loss : 113.37      |       lstm_with_dropout_validation_loss : 144.15      |       \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-771817603d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_base_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEXPERIMENTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-771817603d53>\u001b[0m in \u001b[0;36mrun_exp\u001b[0;34m(experiments)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-70df03ae366b>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train, validation, test, exp_name)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mepoch_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mepoch_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m       \u001b[0mepoch_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_train_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_test_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-70df03ae366b>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     81\u001b[0m       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m       \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_OobxaSzVzY",
        "colab_type": "text"
      },
      "source": [
        "# 7. Visualizing the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dfCUw4xCl5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results_df = pd.concat(results,axis = 1)\n",
        "for exp in EXPERIMENTS:\n",
        "  suffixes =  ['train_loss','validation_loss']\n",
        "  cols = [f\"{exp}_{suffix}\" for suffix in suffixes]\n",
        "  temp_df = results_df[cols]\n",
        "  temp_df.columns =  suffixes \n",
        "  plt.figure()\n",
        "  temp_df.astype(float).plot(title= F\"Train & Validation accuracys for {exp}\")\n",
        "  if SAVE_FIGS:\n",
        "    file_name = F\"{exp}.png\"\n",
        "    plt.savefig(graphs_dir / file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}