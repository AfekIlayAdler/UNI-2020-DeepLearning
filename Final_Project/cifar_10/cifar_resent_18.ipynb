{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cifar_resent_18.ipynb","provenance":[{"file_id":"https://github.com/AfekIlayAdler/UNI-2020-DeepLearning/blob/master/HW1/HW1ModuleDict.ipynb","timestamp":1574334017962}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Y7K1lIKisGq0","colab_type":"text"},"source":["### Or Wolkimir (308402163) and Afek Adler (204249239) \n"]},{"cell_type":"code","metadata":{"id":"Nikv0sDysAov","colab_type":"code","outputId":"b82c6de5-b4e3-47ba-9f7d-fdd970fc0626","executionInfo":{"status":"ok","timestamp":1582455448664,"user_tz":-120,"elapsed":12239,"user":{"displayName":"אור וולקומיר","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBUF3PWxOyv6Dxh3wEom4rsbn2qBgI4CHHUZMWLZsg=s64","userId":"08503908101346450501"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["import numpy as np\n","!pip install tensorboardcolab\n","import torch\n","from torchvision import datasets, transforms\n","import helper\n","from torch import nn, optim\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import summary\n","import datetime\n","import pandas as pd\n","from collections import OrderedDict\n","from os import mkdir\n","from os.path import isdir\n","from glob import glob\n","from pathlib import Path\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import confusion_matrix\n","import torch.nn.init as init\n","from torch.autograd import Variable"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"N2Yyh2w0Bmgj","colab_type":"code","outputId":"4d85d41f-5087-4fea-e6b2-d67ee1b3bb9d","executionInfo":{"status":"ok","timestamp":1582455535722,"user_tz":-120,"elapsed":34338,"user":{"displayName":"אור וולקומיר","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBUF3PWxOyv6Dxh3wEom4rsbn2qBgI4CHHUZMWLZsg=s64","userId":"08503908101346450501"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oJp5M833tW-t","colab_type":"text"},"source":["# 2. Model\n"]},{"cell_type":"code","metadata":{"id":"Mymgu-iotZ3N","colab_type":"code","colab":{}},"source":["class ResnetAll(nn.Module):\n","  def __init__(self,num_classes=10):\n","    super().__init__()\n","    self.linear = nn.Linear(128,num_classes)\n","    self.softmax = nn.LogSoftmax(dim=1)\n","    self.dropout = nn.Dropout(0.1)\n","    self.resnet = ResNet18()\n","\n","  def forward_1(self, x):\n","    return self.resnet(x)\n","\n","  def forward_2(self, x):\n","    x = self.dropout(x)\n","    x = self.linear(x)\n","    x = self.softmax(x)\n","    return x\n","\n","  def forward(self, x):\n","    x1 = self.forward_1(x)\n","    x2 = self.forward_2(x1)\n","    return x2, x1\n","\n","class LambdaLayer(nn.Module):\n","    def __init__(self, lambd):\n","        super(LambdaLayer, self).__init__()\n","        self.lambd = lambd\n","\n","    def forward(self, x):\n","        return self.lambd(x)\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes))\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","  def __init__(self, block, num_blocks, num_classes=10):\n","    super(ResNet, self).__init__()\n","    self.in_planes = 64\n","\n","    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","    self.bn1 = nn.BatchNorm2d(64)\n","    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","    self.linear = nn.Linear(512*block.expansion, 128)\n","\n","  def _make_layer(self, block, planes, num_blocks, stride):\n","    strides = [stride] + [1]*(num_blocks-1)\n","    layers = []\n","    for stride in strides:\n","        layers.append(block(self.in_planes, planes, stride))\n","        self.in_planes = planes * block.expansion\n","    return nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","    out = F.relu(self.bn1(self.conv1(x)))\n","    out = self.layer1(out)\n","    out = self.layer2(out)\n","    out = self.layer3(out)\n","    out = self.layer4(out)\n","    out = F.avg_pool2d(out, 4)\n","    out = out.view(out.size(0), -1)\n","    out = self.linear(out)\n","    return out\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2,2,2,2])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6hCdY13_q0Al","colab_type":"text"},"source":["# 3. Trainer"]},{"cell_type":"code","metadata":{"id":"MDnoTlxf5C9p","colab_type":"code","colab":{}},"source":["class Trainer:\n","  def __init__(self,model, config):\n","    self.model = model\n","    self.model_name = config.model_name\n","    self.seed = config.seed\n","    self.lr = config.lr\n","    self.epochs = config.epochs\n","    self.warmup_epochs = config.warmup_epochs\n","    self.save_model = config.save_model\n","    self.upload_model = config.upload_model\n","    self.model_weights_path = config.model_weights_path\n","    self.batch_size =  config.batch_size\n","    self.dropout_std_n_times = config.dropout_std_n_times\n","    self.momentum = config.momentum\n","    self.milestones = config.milestones\n","    self.gamma = config.gamma\n","    self.save_points = config.save_points\n","    self.optimizer = optim.SGD(self.model.parameters(), lr = self.lr, weight_decay = config.weight_decay, momentum=self.momentum)\n","    #self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=self.milestones, gamma=self.gamma)\n","    torch.manual_seed(self.seed)\n","    self.criterion = nn.NLLLoss(reduction='none')\n","    self.results = {}\n","    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    self.sgd_spv_matrix = {}\n","    self.eps = config.eps\n","    self.per_sample_prediction = None\n","    if torch.cuda.is_available():\n","      self.model.to(self.device)\n","\n","  def get_results(self):\n","    return pd.DataFrame.from_dict(self.results)\n","\n","  def get_test_per_sample_predictions(self):\n","    return self.per_sample_prediction\n","\n","  def record(self,epoch,**kwargs):\n","    epoch = \"{:02d}\".format(epoch)\n","    temp = f\"| epoch   # {epoch} :\"\n","    for key, value in kwargs.items():\n","      key = f\"{self.model_name}_{key}\"\n","      if not self.results.get(key):\n","        self.results[key] =[]\n","      self.results[key].append(value)\n","      val = '{:.4f}'.format(np.round(value,4))\n","      temp += f\"{key} : {val}      |       \"\n","    print(temp)\n","\n","  def load_last_saved_model(self):\n","    starting_epoch = -1\n","    epoch = 1\n","    for point in self.save_points[::-1]:\n","      weights_path = Path(f\"{self.model_weights_path}/{self.model_name}_{point}_seed_{self.seed}.pth\")\n","      if weights_path.exists() and self.upload_model:\n","        epoch_train_accuracy = self.load_checkpoint(weights_path,point)\n","        starting_epoch = point\n","        return starting_epoch,epoch+starting_epoch, epoch_train_accuracy\n","      else:\n","        weights_path = Path(f\"{self.model_weights_path}/baseline_{self.warmup_epochs}_seed_{self.seed}.pth\")\n","        if weights_path.exists() and self.upload_model:\n","          epoch_train_accuracy = self.load_checkpoint(weights_path,self.warmup_epochs)\n","          starting_epoch = self.warmup_epochs\n","          return starting_epoch,epoch+starting_epoch, epoch_train_accuracy\n","    return starting_epoch,epoch, None\n","\n","  def fit(self,trainloader, testloader, exp_name): \n","    train_accu, test_accu, output_plot = [],[],[]\n","    starting_epoch, epoch, epoch_train_accuracy = self.load_last_saved_model()\n","    if epoch==self.epochs+1:\n","      epoch_test_accuracy, test_loss = self.test(testloader,epoch-1)\n","      self.record(epoch-1,\n","                  test_loss = test_loss,\n","                  test_accuracy = epoch_test_accuracy)\n","    self.scheduler = optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=self.milestones, gamma=self.gamma,last_epoch = starting_epoch)\n","    while epoch <= self.epochs:\n","      epoch_train_accuracy, train_loss = self.run_epoch(epoch)\n","      epoch_test_accuracy, test_loss = self.test(testloader,epoch)\n","      self.record(epoch,train_accuracy = epoch_train_accuracy,\n","                  train_losss = train_loss,\n","                  test_loss = test_loss,\n","                  test_accuracy = epoch_test_accuracy)\n","      self.save_checkpoint(epoch_train_accuracy, epoch)\n","      self.scheduler.step()\n","      epoch += 1\n","\n","  def run_epoch(self, epoch):\n","    self.model.train()\n","    train_loss_unweighted , train_accuracy= 0, 0\n","    for i , (images, labels) in enumerate(trainloader):\n","      images = images.to(self.device)\n","      labels = labels.to(self.device)\n","      log_ps, hidden = self.model(images)\n","      accuracy, _ , __ = self.calc_accuracy(log_ps,labels)\n","      loss = self.get_weighted_loss(log_ps,hidden, images, labels, i, epoch) \n","      self.optimizer.zero_grad()\n","      loss.backward()\n","      self.optimizer.step()\n","      train_loss_unweighted += self.criterion(log_ps, labels).mean().item()\n","      train_accuracy += accuracy\n","    epoch_train_accuracy = train_accuracy/len(trainloader)\n","    return epoch_train_accuracy,train_loss_unweighted\n","\n","  def test(self, test_loader, epoch):\n","    self.model.eval()\n","    test_loss,test_accuracy = 0,0\n","    true_labels ,predicted_labels, softmax_p , variance = [], [],[],[]\n","    with torch.no_grad():\n","      for i , (images, labels) in enumerate(test_loader):\n","        images = images.to(self.device)\n","        labels = labels.to(self.device)\n","        log_ps, hidden = self.model(images)\n","        acc, predicted_l, ps_labels = self.calc_accuracy(log_ps,labels)\n","        test_accuracy+=acc\n","        test_loss += self.criterion(log_ps, labels).mean().item()\n","        if epoch==self.epochs: \n","          predicted_labels += predicted_l\n","          true_labels += labels.cpu().tolist()\n","          softmax_p += ps_labels \n","          variance += self.weighted_loss(log_ps, hidden, images, labels, i, epoch, True).view(-1).cpu().tolist()\n","    if epoch==self.epochs:\n","      colnames = ['true_label','p_true_label', 'variance', 'predicted_label'] \n","      per_sample_prediction = pd.DataFrame(np.array([true_labels,softmax_p,variance,predicted_labels]).T, columns = colnames)\n","      self.per_sample_prediction = per_sample_prediction\n","    return test_accuracy/len(test_loader), test_loss\n","\n","  def get_weighted_loss(self,log_ps,hidden, x, y, batch, epoch):\n","    loss = self.criterion(log_ps, y)\n","    if (epoch <= self.warmup_epochs) or self.model_name == 'baseline':\n","      return loss.mean()\n","    else:\n","      epoch_of_weighted_training = epoch - (self.warmup_epochs + 1) \n","      weights = self.weighted_loss(log_ps,hidden,x, y,batch, epoch_of_weighted_training) \n","      return (loss*weights).mean()\n","    \n","\n","  def weighted_loss(self,log_p, hidden, x, labels, batch, epoch_weighted, is_test=False):\n","    total_weighted_epochs = self.epochs - self.warmup_epochs\n","    batch_size = x.size()[0] \n","    #row_indexes = [i for i in range(self.batch_size)]\n","    with torch.no_grad():\n","      weights = torch.ones(batch_size, device= self.device)\n","      if self.model_name == 'MCdropout' or is_test:\n","        self.model.train()\n","        all_p =  torch.zeros((batch_size ,self.dropout_std_n_times), device= self.device)\n","        for i in range(self.dropout_std_n_times):\n","          log_p = self.model.forward_2(hidden)\n","          p = torch.exp(log_p)\n","          p_true_labels = torch.gather(p, 1, labels.view(-1,1))\n","          all_p[:,i] = p_true_labels.view(-1)\n","          weights = all_p.std(axis = 1)\n","        self.model.eval()\n","      elif self.model_name == 'entropy':\n","        weights = -torch.mul(log_p, torch.exp(log_p)).sum(axis = 1)\n","      elif self.model_name == 'SGD-WPV':\n","        self.sgd_spv_matrix.setdefault(batch, torch.zeros((batch_size ,total_weighted_epochs), device= self.device))\n","        # update_matrix\n","        p_true_labels = torch.gather(torch.exp(log_p), 1, labels.view(-1,1))\n","        self.sgd_spv_matrix[batch][:,epoch_weighted] = p_true_labels.view(-1)\n","        if epoch_weighted not in [0,1]:\n","          indexes = [i for i in range(epoch_weighted)]\n","          var = self.sgd_spv_matrix[batch][:,indexes].var(axis = 1)\n","          var +=  var.pow(2)/(len(indexes) -1)\n","          weights = var.sqrt()\n","      weights += self.eps\n","      return (weights)\n","\n","  def calc_accuracy(self, log_ps, labels):\n","    self.model.eval()\n","    ps = torch.exp(log_ps)\n","    top_p, top_class = ps.topk(1, dim=1)\n","    equals = top_class == labels.view(*top_class.shape)\n","    acc = torch.mean(equals.type(torch.FloatTensor))\n","    predicted_lables = top_class.view(-1).cpu().tolist()\n","    ps_labels = torch.gather(ps, 1, labels.view(-1,1))\n","    ps_labels = ps_labels.view(-1).cpu().tolist()\n","    self.model.train()\n","    return acc, predicted_lables, ps_labels\n","\n","  def save_checkpoint(self,loss, epoch):\n","    weights_path_baseline = Path(f\"{self.model_weights_path}/baseline_{self.warmup_epochs}_seed_{self.seed}.pth\")\n","    weights_path_model = Path(f\"{self.model_weights_path}/{self.model_name}_{epoch}_seed_{self.seed}.pth\")\n","    if (epoch == self.warmup_epochs and self.model_name == 'baseline')  and (not weights_path_baseline.exists()) and self.save_model: \n","      print('saving_model: ')\n","      torch.save({'model_state_dict': self.model.state_dict(),\n","              'optimizer_state_dict': self.optimizer.state_dict(),'loss': loss}, weights_path_baseline)\n","    elif (epoch in self.save_points) and (not weights_path_model.exists()) and self.save_model:\n","      print('saving_model: ')\n","      torch.save({'model_state_dict': self.model.state_dict(),\n","              'optimizer_state_dict': self.optimizer.state_dict(),'loss': loss}, weights_path_model) \n","      \n","  def load_checkpoint(self,weights_path,epoch):\n","    checkpoint = torch.load(weights_path)\n","    self.model.load_state_dict(checkpoint['model_state_dict'])\n","    self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    self.model.to(self.device)\n","    loss = checkpoint['loss']\n","    print(f\"Uploaded weights succesfuly at epoch number {epoch}\")\n","    return loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"onXkQpn5q6IV","colab_type":"text"},"source":["# 4. Utils\n","Utility functions for the code"]},{"cell_type":"code","metadata":{"id":"rL71fO5LOKbQ","colab_type":"code","colab":{}},"source":["class Config:  \n","  def __init__(self, **kwargs):\n","    for key, value in kwargs.items():\n","      setattr(self, key, value)\n","\n","  def add_attributes(self,**kwargs):\n","    for key, value in kwargs.items():\n","      setattr(self, key, value)\n","\n","def create_directories(l):\n","  for directory_path in l:\n","    if not (isdir(directory_path)):\n","      mkdir(directory_path)\n","\n","def get_train_test_loaders(batch_size):\n","  # Define a transform to normalize the data\n","  transform_train = transforms.Compose([\n","      transforms.RandomCrop(32, padding=4),\n","      transforms.RandomHorizontalFlip(),\n","      transforms.ToTensor(),\n","      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),])\n","\n","  transform_test = transforms.Compose([\n","      transforms.ToTensor(),\n","      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),])\n","  \n","  # Download and load the training data\n","  trainset = datasets.CIFAR10(root='./data', download=True, train=True, transform=transform_train)\n","  # Download and load the test data\n","  testset = datasets.CIFAR10(root='./data', download=True, train=False, transform=transform_test)\n","  trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle=True)\n","  testloader = torch.utils.data.DataLoader(testset, batch_size= batch_size, shuffle=True)\n","  return trainloader, testloader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nr7RLjwsrGOT","colab_type":"text"},"source":["# 5. Configurations "]},{"cell_type":"code","metadata":{"id":"cayKUt5cjTq3","colab_type":"code","colab":{}},"source":["ROOT_PATH = '/content/drive/My Drive/university/projects/DL/Project/experiments/cifar/resnet18_150/'\n","MODEL_WEIGHTS_DIR = 'model_weights'\n","GRAPHS_FOLDER_NAME = 'graphs'\n","PER_SAMPLE_RESULTS_DIR = 'per_samples_results'\n","model_weights_dir = f\"{ROOT_PATH}{MODEL_WEIGHTS_DIR}\" \n","graphs_dir = f\"{ROOT_PATH}{GRAPHS_FOLDER_NAME}\" \n","sample_results_dir = f\"{ROOT_PATH}{PER_SAMPLE_RESULTS_DIR}\" \n","SAVE_FIGS = True\n","BATCH_SIZE = 128\n","\n","def get_base_config():\n","  ####################################################################\n","  # model consistency options\n","  SAVE_TO_CHECKPOINTS = True # if ture, saves model.name_epcoch file into the weights folder\n","  LOAD_CHECKPOINTS = True # # if ture, every epoch tries to load pretrained weights\n","  ####################################################################\n","  # if needed, can be modified to upload the 'best model'\n","  return Config(lr = 0.0001, \n","                epochs = 170,\n","                warmup_epochs = 150,\n","                eps= 0.00001, \n","                step_size=2, \n","                gamma=0.1, \n","                weight_decay=5e-4,\n","                dropout_std_n_times = 15,\n","                momentum = 0.9, \n","                milestones=[250,350],\n","                save_points=[170],\n","                save_model = SAVE_TO_CHECKPOINTS,\n","                upload_model = LOAD_CHECKPOINTS,\n","                model_weights_path = model_weights_dir,\n","                batch_size = BATCH_SIZE)\n","EXPERIMENTS = ['baseline', 'SGD-WPV', 'MCdropout', 'entropy'\n","              ] # ['MCdropout']# "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qfnNkr9YpB5J","colab_type":"text"},"source":["# 6. Run experiments"]},{"cell_type":"code","metadata":{"id":"07PKWDw5CHZz","colab_type":"code","outputId":"9314c927-f7f9-4962-e2f7-dc38a3b450fe","executionInfo":{"status":"ok","timestamp":1582459747631,"user_tz":-120,"elapsed":4084558,"user":{"displayName":"אור וולקומיר","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBUF3PWxOyv6Dxh3wEom4rsbn2qBgI4CHHUZMWLZsg=s64","userId":"08503908101346450501"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["def run_exp(exp_name,seed):\n","  # create weights directory\n","  create_directories([graphs_dir,model_weights_dir,sample_results_dir])\n","  print(f\"{'#'*50} \\n running {exp_name} experiment\\n{'#'*50} \\n\") \n","  config.add_attributes(model_name = exp_name,seed=seed)\n","  trainer = Trainer(ResnetAll(),config)\n","  trainer.fit(trainloader, testloader, exp_name)\n","  convergence_results = trainer.get_results()\n","  per_sample_results = trainer.get_test_per_sample_predictions()\n","  return convergence_results, per_sample_results\n","\n","config = get_base_config()\n","trainloader, testloader = get_train_test_loaders(BATCH_SIZE)\n","for seed in np.arange(5): \n","  for exp in EXPERIMENTS:\n","    convergence_path = Path(f\"{sample_results_dir}/convergence_results_{exp}_seed_{seed}.csv\")\n","    per_sample_path = Path(f\"{sample_results_dir}/per_sample_results_{exp}_seed_{seed}.csv\")\n","    print (f'{seed},{exp}')\n","    if not (convergence_path.exists() and per_sample_path.exists()):\n","      convergence_results, per_sample_results = run_exp(exp,seed)\n","      convergence_results.to_csv(convergence_path, index=False)\n","      per_sample_results.to_csv(per_sample_path, index=False)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","0,baseline\n","0,SGD-WPV\n","0,MCdropout\n","0,MCdropout\n","################################################## \n"," running MCdropout experiment\n","################################################## \n","\n","Uploaded weights succesfuly at epoch number 150\n","| epoch   # 151 :MCdropout_train_accuracy : 0.9660      |       MCdropout_train_losss : 41.2759      |       MCdropout_test_loss : 21.6563      |       MCdropout_test_accuracy : 0.9071      |       \n","| epoch   # 152 :MCdropout_train_accuracy : 0.9646      |       MCdropout_train_losss : 43.1955      |       MCdropout_test_loss : 19.7625      |       MCdropout_test_accuracy : 0.9190      |       \n","| epoch   # 153 :MCdropout_train_accuracy : 0.9646      |       MCdropout_train_losss : 43.7317      |       MCdropout_test_loss : 18.4687      |       MCdropout_test_accuracy : 0.9224      |       \n","| epoch   # 154 :MCdropout_train_accuracy : 0.9644      |       MCdropout_train_losss : 44.9930      |       MCdropout_test_loss : 17.4198      |       MCdropout_test_accuracy : 0.9285      |       \n","| epoch   # 155 :MCdropout_train_accuracy : 0.9665      |       MCdropout_train_losss : 45.8291      |       MCdropout_test_loss : 17.9198      |       MCdropout_test_accuracy : 0.9265      |       \n","| epoch   # 156 :MCdropout_train_accuracy : 0.9651      |       MCdropout_train_losss : 47.3306      |       MCdropout_test_loss : 17.1304      |       MCdropout_test_accuracy : 0.9278      |       \n","| epoch   # 157 :MCdropout_train_accuracy : 0.9655      |       MCdropout_train_losss : 48.7743      |       MCdropout_test_loss : 17.6202      |       MCdropout_test_accuracy : 0.9292      |       \n","| epoch   # 158 :MCdropout_train_accuracy : 0.9660      |       MCdropout_train_losss : 50.2148      |       MCdropout_test_loss : 17.3962      |       MCdropout_test_accuracy : 0.9308      |       \n","| epoch   # 159 :MCdropout_train_accuracy : 0.9658      |       MCdropout_train_losss : 52.3530      |       MCdropout_test_loss : 17.9573      |       MCdropout_test_accuracy : 0.9306      |       \n","| epoch   # 160 :MCdropout_train_accuracy : 0.9645      |       MCdropout_train_losss : 54.6204      |       MCdropout_test_loss : 18.2929      |       MCdropout_test_accuracy : 0.9300      |       \n","| epoch   # 161 :MCdropout_train_accuracy : 0.9640      |       MCdropout_train_losss : 56.3965      |       MCdropout_test_loss : 19.1904      |       MCdropout_test_accuracy : 0.9295      |       \n","| epoch   # 162 :MCdropout_train_accuracy : 0.9622      |       MCdropout_train_losss : 58.3761      |       MCdropout_test_loss : 20.2888      |       MCdropout_test_accuracy : 0.9279      |       \n","| epoch   # 163 :MCdropout_train_accuracy : 0.9596      |       MCdropout_train_losss : 59.8221      |       MCdropout_test_loss : 21.2955      |       MCdropout_test_accuracy : 0.9299      |       \n","| epoch   # 164 :MCdropout_train_accuracy : 0.9575      |       MCdropout_train_losss : 61.9797      |       MCdropout_test_loss : 23.2506      |       MCdropout_test_accuracy : 0.9249      |       \n","| epoch   # 165 :MCdropout_train_accuracy : 0.9553      |       MCdropout_train_losss : 63.0585      |       MCdropout_test_loss : 25.1943      |       MCdropout_test_accuracy : 0.9245      |       \n","| epoch   # 166 :MCdropout_train_accuracy : 0.9521      |       MCdropout_train_losss : 65.0221      |       MCdropout_test_loss : 28.3760      |       MCdropout_test_accuracy : 0.9201      |       \n","| epoch   # 167 :MCdropout_train_accuracy : 0.9492      |       MCdropout_train_losss : 66.6858      |       MCdropout_test_loss : 31.9416      |       MCdropout_test_accuracy : 0.9154      |       \n","| epoch   # 168 :MCdropout_train_accuracy : 0.9467      |       MCdropout_train_losss : 68.4891      |       MCdropout_test_loss : 35.5486      |       MCdropout_test_accuracy : 0.9107      |       \n","| epoch   # 169 :MCdropout_train_accuracy : 0.9459      |       MCdropout_train_losss : 69.6928      |       MCdropout_test_loss : 40.0765      |       MCdropout_test_accuracy : 0.9044      |       \n","| epoch   # 170 :MCdropout_train_accuracy : 0.9442      |       MCdropout_train_losss : 70.5491      |       MCdropout_test_loss : 18.1771      |       MCdropout_test_accuracy : 0.9235      |       \n","saving_model: \n","0,entropy\n","1,baseline\n","1,baseline\n","################################################## \n"," running baseline experiment\n","################################################## \n","\n","Uploaded weights succesfuly at epoch number 150\n","| epoch   # 151 :baseline_train_accuracy : 0.9627      |       baseline_train_losss : 43.2810      |       baseline_test_loss : 19.0794      |       baseline_test_accuracy : 0.9225      |       \n","| epoch   # 152 :baseline_train_accuracy : 0.9688      |       baseline_train_losss : 36.5307      |       baseline_test_loss : 20.1640      |       baseline_test_accuracy : 0.9195      |       \n","| epoch   # 153 :baseline_train_accuracy : 0.9726      |       baseline_train_losss : 30.7967      |       baseline_test_loss : 19.8682      |       baseline_test_accuracy : 0.9214      |       \n","| epoch   # 154 :baseline_train_accuracy : 0.9767      |       baseline_train_losss : 26.9141      |       baseline_test_loss : 20.4634      |       baseline_test_accuracy : 0.9201      |       \n","| epoch   # 155 :baseline_train_accuracy : 0.9807      |       baseline_train_losss : 23.0828      |       baseline_test_loss : 21.7943      |       baseline_test_accuracy : 0.9153      |       \n","| epoch   # 156 :baseline_train_accuracy : 0.9809      |       baseline_train_losss : 21.7560      |       baseline_test_loss : 21.6311      |       baseline_test_accuracy : 0.9182      |       \n","| epoch   # 157 :baseline_train_accuracy : 0.9831      |       baseline_train_losss : 19.5362      |       baseline_test_loss : 20.4349      |       baseline_test_accuracy : 0.9241      |       \n","| epoch   # 158 :baseline_train_accuracy : 0.9845      |       baseline_train_losss : 17.6036      |       baseline_test_loss : 21.6452      |       baseline_test_accuracy : 0.9222      |       \n","| epoch   # 159 :baseline_train_accuracy : 0.9860      |       baseline_train_losss : 16.4002      |       baseline_test_loss : 21.9560      |       baseline_test_accuracy : 0.9197      |       \n","| epoch   # 160 :baseline_train_accuracy : 0.9882      |       baseline_train_losss : 13.9556      |       baseline_test_loss : 21.4336      |       baseline_test_accuracy : 0.9233      |       \n","| epoch   # 161 :baseline_train_accuracy : 0.9880      |       baseline_train_losss : 14.0427      |       baseline_test_loss : 21.2653      |       baseline_test_accuracy : 0.9228      |       \n","| epoch   # 162 :baseline_train_accuracy : 0.9891      |       baseline_train_losss : 12.7826      |       baseline_test_loss : 21.4494      |       baseline_test_accuracy : 0.9234      |       \n","| epoch   # 163 :baseline_train_accuracy : 0.9897      |       baseline_train_losss : 12.3572      |       baseline_test_loss : 21.9795      |       baseline_test_accuracy : 0.9200      |       \n","| epoch   # 164 :baseline_train_accuracy : 0.9899      |       baseline_train_losss : 11.7663      |       baseline_test_loss : 21.2332      |       baseline_test_accuracy : 0.9256      |       \n","| epoch   # 165 :baseline_train_accuracy : 0.9900      |       baseline_train_losss : 11.9771      |       baseline_test_loss : 21.4797      |       baseline_test_accuracy : 0.9265      |       \n","| epoch   # 166 :baseline_train_accuracy : 0.9899      |       baseline_train_losss : 11.7983      |       baseline_test_loss : 22.6325      |       baseline_test_accuracy : 0.9202      |       \n","| epoch   # 167 :baseline_train_accuracy : 0.9905      |       baseline_train_losss : 11.4946      |       baseline_test_loss : 22.8070      |       baseline_test_accuracy : 0.9223      |       \n","| epoch   # 168 :baseline_train_accuracy : 0.9909      |       baseline_train_losss : 10.9743      |       baseline_test_loss : 24.0799      |       baseline_test_accuracy : 0.9164      |       \n","| epoch   # 169 :baseline_train_accuracy : 0.9893      |       baseline_train_losss : 12.4758      |       baseline_test_loss : 22.8258      |       baseline_test_accuracy : 0.9197      |       \n","| epoch   # 170 :baseline_train_accuracy : 0.9900      |       baseline_train_losss : 11.7994      |       baseline_test_loss : 19.7208      |       baseline_test_accuracy : 0.9350      |       \n","saving_model: \n","1,SGD-WPV\n","1,MCdropout\n","1,entropy\n","1,entropy\n","################################################## \n"," running entropy experiment\n","################################################## \n","\n","Uploaded weights succesfuly at epoch number 150\n","| epoch   # 151 :entropy_train_accuracy : 0.9636      |       entropy_train_losss : 43.1144      |       entropy_test_loss : 19.7961      |       entropy_test_accuracy : 0.9179      |       \n","| epoch   # 152 :entropy_train_accuracy : 0.9679      |       entropy_train_losss : 37.3177      |       entropy_test_loss : 20.0091      |       entropy_test_accuracy : 0.9190      |       \n","| epoch   # 153 :entropy_train_accuracy : 0.9722      |       entropy_train_losss : 32.7321      |       entropy_test_loss : 19.1743      |       entropy_test_accuracy : 0.9240      |       \n","| epoch   # 154 :entropy_train_accuracy : 0.9758      |       entropy_train_losss : 29.4653      |       entropy_test_loss : 19.2898      |       entropy_test_accuracy : 0.9191      |       \n","| epoch   # 155 :entropy_train_accuracy : 0.9781      |       entropy_train_losss : 26.6298      |       entropy_test_loss : 20.3881      |       entropy_test_accuracy : 0.9186      |       \n","| epoch   # 156 :entropy_train_accuracy : 0.9805      |       entropy_train_losss : 24.4438      |       entropy_test_loss : 20.3735      |       entropy_test_accuracy : 0.9203      |       \n","| epoch   # 157 :entropy_train_accuracy : 0.9816      |       entropy_train_losss : 22.6716      |       entropy_test_loss : 19.3985      |       entropy_test_accuracy : 0.9248      |       \n","| epoch   # 158 :entropy_train_accuracy : 0.9832      |       entropy_train_losss : 20.5132      |       entropy_test_loss : 20.6906      |       entropy_test_accuracy : 0.9197      |       \n","| epoch   # 159 :entropy_train_accuracy : 0.9846      |       entropy_train_losss : 19.3059      |       entropy_test_loss : 20.0399      |       entropy_test_accuracy : 0.9227      |       \n","| epoch   # 160 :entropy_train_accuracy : 0.9870      |       entropy_train_losss : 16.7572      |       entropy_test_loss : 19.6180      |       entropy_test_accuracy : 0.9226      |       \n","| epoch   # 161 :entropy_train_accuracy : 0.9870      |       entropy_train_losss : 17.0237      |       entropy_test_loss : 20.6270      |       entropy_test_accuracy : 0.9216      |       \n","| epoch   # 162 :entropy_train_accuracy : 0.9889      |       entropy_train_losss : 15.0506      |       entropy_test_loss : 20.3690      |       entropy_test_accuracy : 0.9216      |       \n","| epoch   # 163 :entropy_train_accuracy : 0.9897      |       entropy_train_losss : 14.0947      |       entropy_test_loss : 19.8828      |       entropy_test_accuracy : 0.9246      |       \n","| epoch   # 164 :entropy_train_accuracy : 0.9901      |       entropy_train_losss : 13.3657      |       entropy_test_loss : 19.9686      |       entropy_test_accuracy : 0.9237      |       \n","| epoch   # 165 :entropy_train_accuracy : 0.9908      |       entropy_train_losss : 12.8265      |       entropy_test_loss : 19.7086      |       entropy_test_accuracy : 0.9240      |       \n","| epoch   # 166 :entropy_train_accuracy : 0.9917      |       entropy_train_losss : 11.9013      |       entropy_test_loss : 20.4904      |       entropy_test_accuracy : 0.9201      |       \n","| epoch   # 167 :entropy_train_accuracy : 0.9916      |       entropy_train_losss : 11.8697      |       entropy_test_loss : 20.8239      |       entropy_test_accuracy : 0.9201      |       \n","| epoch   # 168 :entropy_train_accuracy : 0.9926      |       entropy_train_losss : 11.3613      |       entropy_test_loss : 21.1224      |       entropy_test_accuracy : 0.9167      |       \n","| epoch   # 169 :entropy_train_accuracy : 0.9918      |       entropy_train_losss : 11.7290      |       entropy_test_loss : 21.4944      |       entropy_test_accuracy : 0.9163      |       \n","| epoch   # 170 :entropy_train_accuracy : 0.9914      |       entropy_train_losss : 11.7634      |       entropy_test_loss : 15.7196      |       entropy_test_accuracy : 0.9437      |       \n","saving_model: \n","2,baseline\n","2,SGD-WPV\n","2,MCdropout\n","2,entropy\n","3,baseline\n","3,SGD-WPV\n","3,MCdropout\n","3,entropy\n","4,baseline\n","4,SGD-WPV\n","4,MCdropout\n","4,entropy\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6yw_ajMAmlZN","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]}]}